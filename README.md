# Data Engineering Portfolio

This repository presents a selection of Data Engineering projects that reflect how I approach data systems in real-world environments. The focus is on building pipelines and data models that are reliable, scalable, and easy to maintain.

Rather than showcasing isolated tools, this portfolio emphasizes end-to-end solutions, clear design decisions, and practical trade-offs.

---

## Profile

I’m a Telecommunications Engineer with professional experience in technical consulting, process optimization, and system-level thinking.

My work style is driven by:
- Structuring data systems with clarity and purpose
- Automating workflows to reduce manual effort and operational risk
- Working with measurable objectives, KPIs, and well-defined constraints
- Applying AI and modern data tools to improve efficiency and decision-making

I moved into Data Engineering as it combines engineering discipline with data-driven impact and scalable architectures.

---

## Scope of the portfolio

The projects in this repository cover the core responsibilities of a Data Engineer, including:
- Ingesting data from heterogeneous sources (APIs, files, relational databases)
- Transforming and modeling data for analytical and operational use cases
- Implementing data quality checks and validation logic
- Preparing analytics-ready datasets
- Automating pipelines and managing dependencies
- Documenting systems for long-term maintainability

The scenarios are intentionally designed to resemble production contexts rather than academic or toy problems.

---

## Tools and technologies

The exact stack varies per project, but commonly includes:
- **Languages:** Python, SQL
- **Data processing:** Pandas, PySpark, SQL-based transformations
- **Orchestration:** Airflow, Prefect, or lightweight custom schedulers
- **Storage:** PostgreSQL, DuckDB, cloud object storage
- **Infrastructure:** Docker and basic CI/CD concepts
- **Analytics:** Dimensional modeling and BI-oriented schemas
- **AI support:** LLM-assisted workflows for analysis and automation

Each project documents its architectural choices and tooling rationale.

---

## Repository organization

```text
.
├── projects/
│   ├── project_01_data_pipeline/
│   ├── project_02_analytics_model/
│   └── project_03_automation_case/
│
├── shared_utils/
├── docs/
└── README.md
```

Every project includes:
- A clearly defined problem statement
- Architectural overview and design decisions
- Setup and execution instructions
- Key assumptions and trade-offs
- Identified limitations and improvement areas

## Engineering principles
The work in this repository follows a consistent set of principles:
- Prefer simple, explicit solutions over unnecessary complexity
- Make trade-offs visible and well-documented
- Optimize for maintainability and readability
- Apply scalable patterns even when working with small datasets
- Automate processes when the cost-benefit is clear

## Purpose
This portfolio exists to demonstrate:
- How I reason about data problems
- How I translate requirements into working systems
- How I balance engineering rigor with practical constraints
- It is a living repository that evolves as I learn, experiment, and refine my approach.

## Contact
If you are interested in discussing any project, architectural decision, or potential collaboration, feel free to reach out through GitHub.
Thanks for taking the time to review this work.
